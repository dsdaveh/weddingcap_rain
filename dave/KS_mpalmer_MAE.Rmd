---
title: "MAE calculation with Bootstrapping example"
author: "Dave Hurst"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: 
    html_document:
        css: standard.css

---

Starts with the Kaggle Script mpalmer.R  Original comments are below:

This file calculates the MAE of the entire training set, using the Marshall-Palmer as the predicted values.  MAE for the training set is 23.4304 versus 24.0697 for the test set.

Next I recalulate for 20 random samples of 10% of the dataset.  I plot the resulting histogram.  This technique is essentially bootstrapping, and the median value should be a close approximation of the original (training population).  It should give us an idea of the spread we would expect to see from random samples of the same size.

```{r comments}

# > This is an R implementation of sample_dask.py. It uses the Marshall-Palmer relation
# > to calculate hourly rain rates for each Id. It produces a submission file identical 
# > to the 'sample_solution.csv' file provided in the Data section of this competition
# > to at least 9 decimal places. It earns a MAE score of 24.06968 on the leaderboard 
# > exactly equal to the sample solution benchmark. And it's faster ;)
```

```{r libs, echo=FALSE, message=FALSE, warning=FALSE}

library(dplyr)
library(data.table)
library(Metrics)

source("../team/rain_utils.R")

mpalmer <- function(ref, minutes_past) {
    
    #is there at least one valid ref value
    if ( sum( is.na(ref)) == length(ref) ) return ( -1 )
    
    # order reflectivity values and minutes_past
    sort_min_index = order(minutes_past)
    minutes_past <- minutes_past[sort_min_index]
    ref <- ref[sort_min_index]
    
    # calculate the length of time for which each reflectivity value is valid
    valid_time <- rep(0, length(minutes_past))
    valid_time[1] <- minutes_past[1]
    if (length(valid_time) > 1) {
        for (i in seq(2, length(minutes_past))) {
            valid_time[i] <- minutes_past[i] - minutes_past[i-1]
        }
        valid_time[length(valid_time)] = valid_time[length(valid_time)] + 60 - sum(valid_time)
    } else {
        # if only 1 observation, make it valid for the entire hour
        valid_time <- 60
    }
    
    valid_time = valid_time / 60
    
    # calculate hourly rain rates using marshall-palmer weighted by valid times
    sum <- 0
    for (i in seq(length(ref))) {
        if (!is.na(ref[i])) {
            mmperhr <- ((10^(ref[i]/10))/200) ^ 0.625
            sum <- sum + mmperhr * valid_time[i]
        }
    }
    
    return(sum)
    
}

rdata_file <- "full_train.RData"
if (!exists("train")) {
    tcheck(0)
    if (file.exists( rdata_file )) {
        cat("loading train from RData file\n")
        load( rdata_file )
    } else {
        cat("loading train from CSV\n")
        train <- fread("../train.csv")
    }
}
tcheck()
```

Here's the code and results to check the MAE of the entire population
```{r pop}
rainfall <- train[ ,.(
    yhat = mpalmer(Ref, minutes_past)
    , y = max(Expected)
), Id][ yhat >= 0, ]

mae_trn <- with(rainfall, mae( yhat, y)  )  #23.4304
mae_trn

tcheck()
```

MAE for the entire population of the training set is `r mae_trn` which compares reasonable to the MAE of 24.06968 for the mpalmer script on the public leader board (LB).  

The full training set contains `r length(unique(train$Id))` records, and is unweildy to work with so we want to see what the range MAE values for smaller sets.

```{r setup}
set.seed(2015)
n_id <- length( unique(train$Id) )
n_fold <- 11
fraction <- 0.1
scores <- numeric()
```

Here I'm sampling a fraction = `r fraction*100`% of the data `r n_fold` times and recording the MAE for the sample in `scores`

```{r boot, echo=FALSE}
tcheck(0)
for (i in 1:n_fold) {
    rand_id <- sample(unique(train$Id), round( n_id * fraction ))

    rainfall <- train[ Id== rand_id ,.(
        yhat = mpalmer(Ref, minutes_past)
        , y = max(Expected)
    ), Id][ yhat >= 0, ]

    scores <- c( scores, with(rainfall, mae( yhat, y)  ) )
    tcheck()
}

summary(scores)
hist( scores ) #, breaks= seq(21,26,.5))

tcheck( n_fold + 1)
```

This is essentially bootstrapping, so the following values should be decent approximations of our training (and hopefully test) population.

* Mean of Bootstrapped samples = `r mean(scores)`  
* Median of Bootstrapped samples = `r median(scores)`  
* StDev of Bootstrapped samples = `r sd(scores)`  


